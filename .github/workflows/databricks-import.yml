name: Databricks Import Migration Pipeline

on:
  push:
    branches:
      - dr-import
  workflow_dispatch:

jobs:
  migration:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Set up Databricks profiles
      run: |
        echo "[KELLANOVA_WORKSPACE_SOURCE_NEW]" >> ~/.databrickscfg
        echo "host = https://dbc-f074b72b-99f1.cloud.databricks.com" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_SOURCE }}" >> ~/.databrickscfg
        echo "[KELLANOVA_WORKSPACE_DESTINATION_NEW]" >> ~/.databrickscfg
        echo "host = https://dbc-280cb907-6a02.cloud.databricks.com/" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_DESTINATION }}" >> ~/.databrickscfg
        cat ~/.databrickscfg

    - name: Install dependencies
      run: |
        sudo apt update
        sudo apt install -y python3-pip
        pip3 install setuptools deprecated
        python3 setup.py install

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2  # Change to your region

    - name: Download file from S3
      run: |
        aws s3 cp s3://existing-source-bucket-1/backups_123.zip backups_123.zip

    - name: Unzip backups folder
      run: |
        unzip -j backups_123.zip -d ../backups/

    - name: Move source_info.txt to logs/sample/
      run: |
        mkdir -p logs/sample/
        mv ../backups/source_info.txt logs/sample/
        
    - name: Run Databricks Migration Pipeline
      run: |
        SRC_PROFILE=KELLANOVA_WORKSPACE_DESTINATION_NEW
        python3 migration_pipeline.py --profile $SRC_PROFILE --import-pipeline --use-checkpoint --session sample --no-prompt --skip-tasks users workspace_acls
